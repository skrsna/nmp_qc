{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_BIG_NEGATIVE = -1000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell_hidden(mprev, cprev, node_dim, attention_m=False):\n",
    "    \"\"\"\n",
    "    Create an LSTM cell.\n",
    "\n",
    "    The way this LSTM cell is\n",
    "    used, there is no input x, instead the m and c are updated according to the\n",
    "    LSTM equations treating the input x as the zero vector. However the m at each\n",
    "    time step is concatenated with an external input as described in\n",
    "    https://arxiv.org/pdf/1511.06391.pdf.\n",
    "\n",
    "    Implements the equations in pg.2 from\n",
    "    \"Long Short-Term Memory Based Recurrent Neural Network Architectures\n",
    "    For Large Vocabulary Speech Recognition\",\n",
    "    Hasim Sak, Andrew Senior, Francoise Beaufays.\n",
    "\n",
    "    Args:\n",
    "    mprev: m_{t-1}, the recurrent activations (same as the output)\n",
    "      from the previous cell.\n",
    "    cprev: c_{t-1}, the cell activations from the previous cell.\n",
    "    node_dim: Number of hidden state of the LSTM.\n",
    "    attention_m: If true then the hidden dim is twice the size of the cell dim\n",
    "    name: prefix for the variable names\n",
    "\n",
    "    Returns:\n",
    "    m: Outputs of this cell.\n",
    "    c: Cell Activations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input Gate\n",
    "    m_nodes = node_dim\n",
    "    if attention_m:\n",
    "        m_nodes = 2 * node_dim\n",
    "    im = Variable(torch.rand(m_nodes,node_dim))\n",
    "    ib = Variable(torch.zeros(1,node_dim))\n",
    "    i_g  = torch.sigmoid(torch.matmul(mprev,im) + ib)\n",
    "    \n",
    "    #Forget Gate\n",
    "    fm = Variable(torch.rand(m_nodes,node_dim))\n",
    "    fb = Variable(torch.zeros(1,node_dim))\n",
    "    f_g = torch.sigmoid(torch.matmul(mprev,fm) + fb)\n",
    "    \n",
    "    #Cell\n",
    "    cm = Variable(torch.rand(m_nodes,node_dim))\n",
    "    cb = Variable(torch.zeros(1,node_dim))\n",
    "    cprime = torch.sigmoid(torch.matmul(mprev,cm) + cb)\n",
    "    c = f_g * cprev + i_g * torch.tanh(cprime)\n",
    "    \n",
    "    #Output Gate\n",
    "    om = Variable(torch.rand(m_nodes,node_dim))\n",
    "    ob = Variable(torch.zeros(1,node_dim))\n",
    "    o_g = torch.sigmoid(torch.matmul(mprev,om) + ob)\n",
    "    m = o_g * torch.tanh(c)\n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set2vec(input_set,\n",
    "            num_timesteps,\n",
    "            mprev=None,\n",
    "            cprev=None,\n",
    "            mask=None,\n",
    "            inner_prod=\"default\"):\n",
    "    \"\"\"\n",
    "  Part of the set2set model described in Vinyals et. al.\n",
    "\n",
    "  Specifically this implements the \"process\" block described in\n",
    "  https://arxiv.org/pdf/1511.06391.pdf. This maps a set to a single embedding\n",
    "  m which is invariant to the order of the elements in that set. Thus it should\n",
    "  be thought of as a \"set2vec\" model. It is part of the full set2set model from\n",
    "  the paper.\n",
    "\n",
    "  There is an LSTM which from t = 1,...,num_timesteps emits a query vector at\n",
    "  each time step, which is used to perform content based attention over the\n",
    "  embedded input set (see https://arxiv.org/pdf/1506.03134.pdf sec 2.2), and\n",
    "  the result of that content based attention is then fed back into the LSTM\n",
    "  by concatenation with m, the output of the LSTM at that time step. After\n",
    "  num_timesteps of computation we return the final cell c, and output m.\n",
    "  m can be considered the order invariant embedding of the input_set.\n",
    "\n",
    "  Args:\n",
    "    input_set: tensor of shape [batch_size, num_nodes, 1, node_dim]\n",
    "    num_timesteps: number of computation steps to run the LSTM for\n",
    "    mprev: Used to initialize the hidden state of the LSTM, pass None if\n",
    "      the hidden state should be initialized to zero.\n",
    "    cprev: Used to initialize the cell of the LSTM, pass None if the cell\n",
    "      state should be initialized to zero.\n",
    "    mask: tensor of type bool, shape = [batch_size,num_nodes]. This is\n",
    "      used when batches may contain sets of different sizes. The values should\n",
    "      be binary. If set to None then the model will assume all sets have the\n",
    "      same size.\n",
    "    inner_prod: either 'default' or 'dot'. Default uses the attention mechanism\n",
    "      as described in the pointer networks paper. Dot is standard dot product.\n",
    "      The experiments for the MPNN paper (https://arxiv.org/pdf/1704.01212.pdf)\n",
    "      did not show a significant difference between the two inner_product types,\n",
    "      and the final experiments were run with default.\n",
    "    name: (string)\n",
    "\n",
    "  Returns:\n",
    "    logit_att: A list of the attention masks over the set.\n",
    "    c: The final cell state of the internal LSTM.\n",
    "    m: The final output of the internal LSTM (note this is what we use as the\n",
    "      order invariant representation of the set).\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If an invalid inner product type is given.\n",
    "  \"\"\"\n",
    "    batch_size = input_set.shape[0]\n",
    "    node_dim = input_set.shape[3]\n",
    "    # For our use case the \"input\" to the LSTM at each time step is the\n",
    "    # zero vector, instead the hidden state of the LSTM at each time step\n",
    "    # will be concatenated with the output of the content based attention\n",
    "    # (see eq's 3-7 in the paper).\n",
    "    if mprev is None:\n",
    "        mprev = torch.zeros(batch_size,node_dim)\n",
    "    mprev = torch.cat((mprev,torch.zeros(batch_size,node_dim)),1)\n",
    "    \n",
    "    if cprev is None:\n",
    "        cprev = torch.zeros(batch_size,node_dim)\n",
    "    \n",
    "    \n",
    "    logit_att = []\n",
    "    attention_w2 = Variable(torch.rand(node_dim,node_dim))\n",
    "    attention_v = Variable(torch.rand(node_dim,1))\n",
    "    # Batches may contain sets of different sizes, in which case the smaller\n",
    "    # sets will be padded with null elements as specified by the mask.\n",
    "    # In order to make the set2vec model invariant to this padding, we add\n",
    "    # large negative numbers to the logits of the attention softmax (which when\n",
    "    # exponentiated will become 0).\n",
    "    if mask is not None:\n",
    "        mask = (1 - mask) * _BIG_NEGATIVE\n",
    "        \n",
    "    for i in range(num_timesteps):\n",
    "        m,c = lstm_cell_hidden(\n",
    "               mprev,cprev,node_dim,attention_m=True)\n",
    "        query = torch.matmul(m,attention_w2)\n",
    "        query = torch.reshape(query,(-1,1,1,node_dim))\n",
    "        if inner_prod == 'default':\n",
    "            energies = torch.reshape(\n",
    "                        torch.matmul(\n",
    "                                torch.reshape(torch.tanh(query+input_set),(-1,node_dim)),\n",
    "                                attention_v),(batch_size,-1))\n",
    "        elif inner_prod == 'dot':\n",
    "            att_mem_reshape = torch.reshape(input_set,(batch_size,-1,node_dim))\n",
    "            query = torch.reshape(query,(-1,node_dim,1))\n",
    "            energies = torch.reshape(\n",
    "                        torch.matmul(att_mem_reshape,query),(batch_size,-1))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid inner_prod type: {}\".format(inner_prod))\n",
    "        #Zero out non nodes\n",
    "        if mask is not None:\n",
    "            energies += mask\n",
    "        att = torch.nn.softmax(energies)\n",
    "        \n",
    "        #multiply attention mask over the elements of the set\n",
    "        att = torch.reshape(att,(batch_size,-1,1,1))\n",
    "        # Take the weighted average the elements in the set\n",
    "        # This is the 'r' of the paper.\n",
    "        read_mult = att * input_set\n",
    "        read = read_mult.sum(1).sum(2)\n",
    "        m = torch.cat((m,read),1)\n",
    "        \n",
    "        logit_att.append(m)\n",
    "        mprev = m\n",
    "        cprev = c\n",
    "        return logit_att,c,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
